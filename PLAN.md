# Plano – próximos passos
- [x] Plano rápido – corrigir warnings de fragmentação
  - [x] Identificar onde `df_proc[name] = series` é chamado em loop no notebook e mapear colunas criadas.
  - [x] Refatorar o pré-processamento para criar colunas derivadas em bloco com `pd.concat`/`assign`, evitando inserts repetidos.
  - [x] Garantir consistência da lista de colunas entre train/val/test e sincronizar notebook com jupytext.
- [x] Guia Pearson/ensemble (foco em correlação e direção)
  - [x] Estruturar notebook com seções (cabeçalho/config com scorer Pearson, leitura/cheques, engenharia de sinais fracos, validação temporal, modelos base, ensemble, robustez, inferência, log).
  - [x] Engenharia de features: momentum acumulado (3/5/10/20), reversão (desvio de média/Bollinger), scalers cross-section por dia (rank/z), winsor/clip leve; incluir macro/FX/commodities defasadas se permitido.
  - [x] Validação temporal com purge/embargo ou rolling (ex. 60/20), métrica Pearson por janela; gráficos de distribuição de correlação e série temporal da correlação.
  - [x] Modelos base orientados a direção: Ridge/ElasticNet com features z/rank, LightGBM raso, regressão logística no sinal (target binário [-1,1]), KNN rank-based opcional.
  - [x] Ensemble focado em rank/sinal: blending recursivo/meta-modelo (Ridge) nos ranks das previsões, shrinkage de pesos (inverso da variância de erro), stacking time-aware com ranks/quantis, calibração final via rank/quantil por dia.
  - [x] Estabilidade e robustez: backtest por regimes de vol, turnover de rank por dia, sensibilidade a lags e drift de distribuição.
- [x] Inferência e submissão: pipeline determinístico (mesmos scalers por data), pós-processamento `groupby(date_id).rank`/z-score para [-1,1], export CSV com checagens de integridade.
- [x] Diário de experimentos: log curto com features+modelo, CV Pearson (média/desvio), pesos do ensemble, seeds e observações de estabilidade; guardar snippets úteis (scorer Pearson, rank_by_day, pesos com shrinkage).
- [x] Dicas táticas: padronizar por dia, otimizar para Pearson no CV, gerar predições rankeadas, priorizar diversidade de sinais fracos e shrinkage nos pesos.
- [ ] Modelagem — pesos e Optuna
  - [x] Revisar CV/treino LGBM para incluir pesos em `is_scored` e variante train_only_scored quando aplicável.
  - [x] Fortalecer bloco do Optuna focando 4–5 hiperparâmetros-chave, trials ~40, e deixar `study.optimize` pronto para uso.
  - [x] Incluir variantes LGBM (conservadora/weighted) no pipeline de CV/ensemble e refletir no treino final/submissão.
  - [x] Sincronizar notebook `.py` ↔ `.ipynb` com `jupytext --sync` após ajustes.
- [ ] Treino final — scored vs não scored
  - [x] Comparar três variantes no holdout/CV: (1) treino full; (2) `train_only_scored=True`; (3) pesos `weight_scored=1`, `weight_unscored=0.2` no fit.
  - [x] Escolher a variante que melhor alinha CV e holdout (Sharpe mod/vol) e aplicar também no `train_full_and_predict_model`.
  - [x] Documentar decisão e checagens (incluindo o porquê da escolha) no diário/observações do notebook.
- [x] Pipeline único CV ↔ treino final
  - [x] Extrair função única `make_features(train, test, target, intentional_cfg, fe_cfg)` para aplicar o pipeline completo (lags → agregações → regimes → intencionais → winsor/ratios → normas cross-section → surprise → combos) com `fit_ref`.
  - [x] Usar essa função em todas as rotas (CV principal, diagnósticos/baselines, treino final/submissão) em vez de pipelines paralelos.
  - [x] Garantir alinhamento de colunas entre train/test e ausência de NaN/constantes inesperadas antes do `preprocess_basic`.
  - [x] 3.2: reforçar uso único do pipeline de features no treino final (gerar/regarantir colunas com `make_features` quando faltarem).
- [x] Ajustar chamadas do treino final/submissão para usar `feature_set`/`fe_cfg` consistentes com a CV.
  - [x] Sincronizar notebook `.py` ↔ `.ipynb` após o ajuste.
- [x] Modularização Kaggle-safe
  - [x] Extrair helpers de feature/preprocess para `src/hull_features.py`.
  - [x] Materializar/importar `hull_features.py` dentro do notebook (compatível com Kaggle offline).
  - [x] Validar com `py_compile` + `jupytext --sync`.
- [ ] Corrigir CV fit_ref (ValueError em prepare_features)
  - [x] Identificar e remover/deduplicar colunas que ainda chegam duplicadas no fluxo do `time_cv_lightgbm_fitref`/`build_feature_sets`, evitando que `df_sorted[c]` retorne DataFrame e gere “truth value of a Series is ambiguous”.
  - [x] Validar `time_cv_lightgbm_fitref` rodando sem erros com o feature set `D_intentional` após o ajuste (ajuste aplicado; rodar a célula para confirmar em runtime).
- [x] Modularização notebook → src
  - [x] Mapear blocos de código reutilizáveis no `notebooks/Hull Tactical.py` (features, validação, treino, inferência).
  - [x] Extrair funções/helpers faltantes para `src/` (ex.: treino LightGBM, CV time-aware, pós-processamento), mantendo assinatura compatível com Kaggle.
  - [x] Atualizar o notebook para consumir os helpers modularizados e reduzir código duplicado.
  - [x] Validar importação (`py_compile`/execução a seco) e sincronizar com `jupytext --sync`.
