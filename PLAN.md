# Plano – próximos passos
- [x] STOP-SHIP: segurança de credenciais
  - [x] Remover fluxo de credenciais Kaggle do notebook (sem hard-code).
  - [x] Adicionar `.env.example` e endurecer `.gitignore` para arquivos de segredo.
  - [x] Adicionar scan simples de segredos (`scripts/scan_secrets.py`).
  - [x] Bloquear `kaggle.json` dentro do repo (mesmo ignorado) e detectar via scan local.
  - [x] Reescrever histórico git para remover credenciais antigas do notebook.
- [x] Plano rápido – corrigir warnings de fragmentação
  - [x] Identificar onde `df_proc[name] = series` é chamado em loop no notebook e mapear colunas criadas.
  - [x] Refatorar o pré-processamento para criar colunas derivadas em bloco com `pd.concat`/`assign`, evitando inserts repetidos.
  - [x] Garantir consistência da lista de colunas entre train/val/test e sincronizar notebook com jupytext.
- [x] Guia Pearson/ensemble (foco em correlação e direção)
  - [x] Estruturar notebook com seções (cabeçalho/config com scorer Pearson, leitura/cheques, engenharia de sinais fracos, validação temporal, modelos base, ensemble, robustez, inferência, log).
  - [x] Engenharia de features: momentum acumulado (3/5/10/20), reversão (desvio de média/Bollinger), scalers cross-section por dia (rank/z), winsor/clip leve; incluir macro/FX/commodities defasadas se permitido.
  - [x] Validação temporal com purge/embargo ou rolling (ex. 60/20), métrica Pearson por janela; gráficos de distribuição de correlação e série temporal da correlação.
  - [x] Modelos base orientados a direção: Ridge/ElasticNet com features z/rank, LightGBM raso, regressão logística no sinal (target binário [-1,1]), KNN rank-based opcional.
  - [x] Ensemble focado em rank/sinal: blending recursivo/meta-modelo (Ridge) nos ranks das previsões, shrinkage de pesos (inverso da variância de erro), stacking time-aware com ranks/quantis, calibração final via rank/quantil por dia.
  - [x] Estabilidade e robustez: backtest por regimes de vol, turnover de rank por dia, sensibilidade a lags e drift de distribuição.
- [x] Inferência e submissão: pipeline determinístico (mesmos scalers por data), pós-processamento `groupby(date_id).rank`/z-score para [-1,1], export CSV com checagens de integridade.
- [x] Diário de experimentos: log curto com features+modelo, CV Pearson (média/desvio), pesos do ensemble, seeds e observações de estabilidade; guardar snippets úteis (scorer Pearson, rank_by_day, pesos com shrinkage).
- [x] Dicas táticas: padronizar por dia, otimizar para Pearson no CV, gerar predições rankeadas, priorizar diversidade de sinais fracos e shrinkage nos pesos.
- [ ] Modelagem — pesos e Optuna
  - [x] Revisar CV/treino LGBM para incluir pesos em `is_scored` e variante train_only_scored quando aplicável.
  - [x] Fortalecer bloco do Optuna focando 4–5 hiperparâmetros-chave, trials ~40, e deixar `study.optimize` pronto para uso.
  - [x] Incluir variantes LGBM (conservadora/weighted) no pipeline de CV/ensemble e refletir no treino final/submissão.
  - [x] Sincronizar notebook `.py` ↔ `.ipynb` com `jupytext --sync` após ajustes.
- [ ] Treino final — scored vs não scored
  - [x] Comparar três variantes no holdout/CV: (1) treino full; (2) `train_only_scored=True`; (3) pesos `weight_scored=1`, `weight_unscored=0.2` no fit.
  - [x] Escolher a variante que melhor alinha CV e holdout (Sharpe mod/vol) e aplicar também no `train_full_and_predict_model`.
  - [x] Documentar decisão e checagens (incluindo o porquê da escolha) no diário/observações do notebook.
- [x] Pipeline único CV ↔ treino final
  - [x] Extrair função única `make_features(train, test, target, intentional_cfg, fe_cfg)` para aplicar o pipeline completo (lags → agregações → regimes → intencionais → winsor/ratios → normas cross-section → surprise → combos) com `fit_ref`.
  - [x] Usar essa função em todas as rotas (CV principal, diagnósticos/baselines, treino final/submissão) em vez de pipelines paralelos.
  - [x] Garantir alinhamento de colunas entre train/test e ausência de NaN/constantes inesperadas antes do `preprocess_basic`.
  - [x] 3.2: reforçar uso único do pipeline de features no treino final (gerar/regarantir colunas com `make_features` quando faltarem).
- [x] Ajustar chamadas do treino final/submissão para usar `feature_set`/`fe_cfg` consistentes com a CV.
  - [x] Sincronizar notebook `.py` ↔ `.ipynb` após o ajuste.
- [x] Modularização Kaggle-safe
  - [x] Extrair helpers de feature/preprocess para `src/hull_features.py`.
  - [x] Materializar/importar `hull_features.py` dentro do notebook (compatível com Kaggle offline).
  - [x] Validar com `py_compile` + `jupytext --sync`.
  - [x] Robustecer bootstrap de import do `src/` (Kaggle `/kaggle/input`, Colab `/content` e opção de auto-clone).
- [ ] Corrigir CV fit_ref (ValueError em prepare_features)
  - [x] Identificar e remover/deduplicar colunas que ainda chegam duplicadas no fluxo do `time_cv_lightgbm_fitref`/`build_feature_sets`, evitando que `df_sorted[c]` retorne DataFrame e gere “truth value of a Series is ambiguous”.
  - [x] Validar `time_cv_lightgbm_fitref` rodando sem erros com o feature set `D_intentional` após o ajuste (ajuste aplicado; rodar a célula para confirmar em runtime).
- [x] Modularização notebook → src
  - [x] Mapear blocos de código reutilizáveis no `notebooks/01_research.py` (features, validação, treino, inferência).
  - [x] Extrair funções/helpers faltantes para `src/` (ex.: treino LightGBM, CV time-aware, pós-processamento), mantendo assinatura compatível com Kaggle.
  - [x] Atualizar o notebook para consumir os helpers modularizados e reduzir código duplicado.
  - [x] Validar importação (`py_compile`/execução a seco) e sincronizar com `jupytext --sync`.
- [x] Refinos pós-modularização
  - [x] Quebrar funções grandes de treino/predição em helpers menores e reutilizáveis em `src/hull_tactical/models.py`.
  - [x] Reduzir dependência de globais criando setter explícito para colunas (market/rf/is_scored) e passando-as aos helpers-chave.
  - [x] Evitar duplicação na materialização de módulos no notebook com helper único de cópia.
  - [x] Adicionar testes leves em `tests/` para métricas e preparação de dados (ex.: `adjusted_sharpe_score`, splits, preparação de matrizes).
- [ ] Estrutura de pacote hull_tactical
  - [x] Transformar `src/` em pacote (`src/hull_tactical/` com `__init__.py`).
  - [x] Mover/renomear `hull_features.py` → `hull_tactical/features.py` e `hull_modeling.py` → `hull_tactical/models.py`.
  - [x] Adicionar módulos básicos `data.py` (load/split) e `pipeline.py` (pipeline mínimo de treino/submissão).
  - [x] Ajustar notebook/testes para importar `hull_tactical.*` e materializar pacote para uso offline.
  - [x] Detalhar agents em `src/hull_tactical/agents/` com stubs (data/feature/training/eval/submission).
- [ ] Clarificar feature sets vs pipeline
  - [x] Documentar em `features.py` os nomes/descrições dos feature sets expostos.
  - [x] Garantir notebook e scripts referenciam apenas `make_features`/feature_sets documentados.
- [ ] Estratégia de alocação (Sharpe) — calibração e risco
  - [x] Criar módulo dedicado de allocation (global k/alpha, regime scaling, vol targeting, smoothing).
  - [x] Expandir `run_cv_preds`/OOF para guardar colunas de regime/date_id.
  - [x] Calibrar k/alpha global em OOF (com smoothing) e aplicar no treino final.
  - [x] Atualizar CV/Optuna para usar Sharpe OOF com fit_ref + allocation avançada.
  - [x] Ensemble por predição (OOF) + calibração global (mean/weighted/stacking Ridge).
  - [x] Treino final: blend de predições e allocation aplicado 1x.
  - [x] Adicionar testes guardrail (penalidades, regime/risk e CV OOF).
  - [x] Atualizar notebook e sincronizar via jupytext.
- [x] Estrutura de repositório (research vs submission)
  - [x] 3.1: Separar notebooks `01_research` e `02_submission` (jupytext).
  - [x] 3.2: Centralizar configs em `configs/` (`features.yaml`, `lgb.yaml`, `run.yaml`) + loader em `src/hull_tactical/config.py`.
  - [x] 3.3: Testes mínimos (`tests/test_metric.py`, `tests/test_features.py`) cobrindo métrica e guardrails de features/fit_ref.
  - [x] 3.4: Remover “gordura” (cross-sectional por `date_id`) e manter só FE temporal (lags/rolling/ratios).
  - [x] Ajustar `scripts/` para ler YAML (CV/treino/submissão) e reduzir mudanças manuais no notebook.
  - [x] Atualizar `AGENTS.md`/docs para o novo fluxo e rodar smoke-check (`pytest`, `py_compile`).
- [x] Pontuação — alinhar CV/treino/alloc
  - [x] 4.1: Alinhar treino final à CV (mesmo pipeline de features + num_boost_round + policy).
  - [x] 4.2: Congelar policy `is_scored` em `configs/run.yaml` e aplicar em CV/treino final.
  - [x] 4.3: Calibração global OOF (k/alpha) + smoothing/vol-targeting via `AllocationConfig`.
  - [x] 4.3b: Evitar tuning de (k, alpha) no fold de validação (CV menos otimista).
  - [x] 4.3c: Endurecer CV temporal com `gap` (purge) e peso no último fold.
  - [x] 4.4: Manter `02_submission` simples (bagging leve + allocation única).
- [x] Kaggle-ready (Code Submission / ambiente restrito)
  - [x] Remover qualquer fluxo de credenciais Kaggle do notebook/repo (sem criação de `kaggle.json`).
  - [x] Garantir que leitura use `/kaggle/input/...` no Kaggle e escrita vá para `/kaggle/working/...` (sem tentar gravar em `/kaggle/input`).
  - [x] Separar scripts: `train.py` (offline, salva artefatos) e `infer.py` (só inferência, rápido).
  - [x] Extrair `metric.py` com a métrica oficial (sem depender de `models.py`).
  - [x] Garantir `features.py` causal (sem leakage) e documentar invariantes.
  - [x] Smoke-check: `python scripts/scan_secrets.py --history` + `pytest`.
- [x] Guardrail leakage de forward/target
  - [x] Adicionar assert no pipeline de features para bloquear `forward_returns`/`market_forward_excess_returns`/`target` (exceto versões `lagged_`) em `feature_cols`.
  - [x] Cobrir com teste rápido reforçando o guardrail (além dos testes existentes).
  - [x] Sincronizar jupytext se alguma célula/notebook for tocada (se aplicável).
- [x] Notebook reforços (delta vs baseline e baseline de risco)
  - [x] Inserir assert explícito de leakage nos `feature_sets` do `01_research`.
  - [x] Adicionar blocos de diagnóstico: Sharpe vs baseline (delta por fold/percentis) e baseline de risco sem predição.
  - [x] Sincronizar notebook (`jupytext --sync notebooks/01_research.ipynb`).
- [x] Walk-forward curto e baseline direcional
  - [x] Adicionar CV com janelas menores (30–120 dias) no notebook.
  - [x] Adicionar baseline direcional (lags/regime) para checar ganho sem modelo.
  - [x] Sincronizar jupytext.
